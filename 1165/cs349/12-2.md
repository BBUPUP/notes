# Cognition

CS 349 - User interfaces (whichever section I decide to go to)

7-22-2016

Elvin Yung

[Slides](https://www.student.cs.uwaterloo.ca/~cs349/s16/slides/12.2-perception_cognition.pdf)

* We've talked about [physical](11-2.md) and [visual](12-1.md) capabilities. Now we'll talk about cognitive capabilities.
* Ergonomic research generally focuses on the physical side of things, but doesn't really cover anything on the cognitive side.

* Instead, this is covered in a field called *cognetics*.
* One of the pioneers of this field is [Jef Raskin](http://www.folklore.org/ProjectView.py?project=Macintosh&characters=Jef%20Raskin), the lead of the Macintosh team before he got kicked out by Steve Jobs.

* We want to cover mental processes like attention, memory, learning, and reasoning.
* [Model Human Processor](http://www2.parc.com/istl/groups/uir/publications/items/UIR-1986-05-Card.pdf) - try to treat humans like machines, to measure processing capabilities, etc.
  * Compelling, but doesn't work!

## Memory
* We tend to think of memory as short and long term.
* **Short-term** memory is what you're paying attention to right now, basically the current "working set".
* **Long-term** memory is information that is/should be retained over a long term.

* It's tempting to think of the human memory model as perceptions getting input into short-term memory, which eventually gets flushed to long-term memory, but it isn't that simple!
* It's maybe more accurate to think of the short-term memory
* Also, long-term memory isn't really as concrete as you think - it's really more nebulous than than.


A rough model:
* Your perceptions (i.e. visual, auditory, olfactory, tactile, etc.) map to neurons.
* As data comes in, different neurons in the brain get activated.
* Combinations of different sensory input features get combined into higher-level features in
* The more similar perceptual stimuli are, they get

* Memory is really a set of patterns that you repeat over and over again.
* Memory is *formed* essentially when some neural activity pattern is easier to reactivate in the future.
* **Remembering** is when the same neural activity patterns is reactivated.
* Somehow the brain can figure out a "new" pattern from a reactivation.
* **Recognition**: new perceptions that trigger some existing pattern.
* **Recall**: trigger pattern without some sort of stimulus.
* The strength of the memory depends on how often you remember it, how strong the original perception was, and sleep.

### Short-term Memory
* Short-term memory is *not* just temporary neural activity.
* Instead, think of it as a combination of perception and attention, kind of like RAM.
* You choose what you want to look at, and your brain chooses what to focus on.
* Short-term memory is, then, the currently activated neural pattern.

* Short-term memory is very low capacity and volatile.
* The general rule is that the average person can memory 7 ± 2 items.
  * More recent research says 6 ± 5!
  * Also, this depends on the similarity of the items, and our ability to cluster items.
  * For example, phone numbers are easier to remember than a bunch of arbitrary numbers.
* If you're easily distracted, you have a hard time keeping things in short-term memory.
* Basically, in general it's super super volatile, and it's really easy to lose things.
* For design, this means that you can't rely on people to remember things.

#### Implications for UI
* Interfaces should *help* people remember thing!
* Never expect people to remember things across different views/modes/etc.
* If the user doesn't have to keep state in their head, they can be purely functional :P

* For search results: Keep search results displayed, so people can remember what they're working with.
* Instructions: Keep the steps visible while they're being followed.

### Long-term Memory
* You don't have as much storage as you think you do, so your brain is compressing things as time goes on.
* But eventually things get lost.
* You might remember bits and pieces, and your brain might fill in the missing parts.
* Emotions can affect them.
* Retroactively alterable

#### Implications for UI
* Don't burden the long term memory.
* Example: those annoying security questions
  * People generally forget the questions, and forget the answers.
  * Even if they remember the answer, they probably won't remember the exact case, punctuations etc.

## Perception
* Our perception of the world is "wrong".
* Everyone has their own personal [reality distortion field](https://en.wikipedia.org/wiki/Reality_distortion_field).

### By Experience
* Really good example in slides, hard to copy here.
* After interacting with a dialog box a few times, muscle memory sets in, and people stop paying attention.

### By Context
* e.g. phrases perceived differently depending on context.

>>>Fold napkins. Polish silverware. Wash dishes.
French napkins. Polish silverware. German dishes.

### By Goals
* When you're looking for something specific, your brain becomes desensitized to unrelated things.
* Your goal also influences where you look.
* That [Selective Attention video](https://www.youtube.com/watch?v=vJG698U2Mvo) that everyone's already seen

## Cognition
* **Cognitive unconscious**: Processes that you're not aware of doing when it happens.
  * Basically, things happening on a "background thread.
  * Generally for repetitive stuff like walking, breathing, etc.
  * The cognitive unconscious is what lets you work in your day-to-day life.
  * Potentially many things being processed in parallel.
* **Cognitive conscious**: Things that happen that you're aware of when they happen.
  * Generally good at focusing at a very small number of things.
  * Tiny capacity, generally sequential
  * Basically, "foreground" processing - what you generally consider as "thinking".

// TODO: copy table from slides

* According to Jef Raskin, it's essential to recognize these types of cognition when designing a human-machine interface.

### Locus
* **Locus** is the one thing you're actively focusing on.
* As much as we like to think that people can control what you think, but this isn't completely true.
* You can sort of guide your locus, but you don't have complete control over it.
* You have *at most* one locus.
* Since you only have one, when you're multitasking, you're not really multiprocessing. Just like with preempting threads, you incur overhead.
  * (Limited multiprocessing *is* possible by combining a locus and some automatic unconscious activities.)
* For apps: don't encourage users to multitask!

* A downside of a singe locus is that you might hyperfocus.
* For example, if you're writing an essay with a minimum word count, you might focus on the word count in the word processing program, and ignore the fact that there are spelling errors.
* As a designer, you should be careful not to overload things on one spot.

* The danger of things like "low battery" dialogs: since they're irrelevant to what you're currently doing, it's easy to ignore them, and it becomes a habit.
* **Change blindness**: If there's a change of something unrelated to what you're looking at, you tend not to notice it.
  * Magicians exploit this.

### Context Switches
* **Context switch**: a switch from one locus of attention to another.
* As a programmer, you've probably experienced being in "[the zone](https://en.wikipedia.org/wiki/Flow_(psychology))", and then being snapped out of it.
* The cost is about 10 seconds, ridiculously expensive.
* Lots of HCI research in interruptibility indicates that this is very damaging to productivity.
* This also means that things like push notifications are really bad.

### Absorption
* You can be completely absorbed in your locus of attention.
* Absorption is essential for high productivity - flow/being in the zone
* As a designer, take great pains not to take people out of this.

* Negative side: it's possible to get so absorbed, it's possible to not pay attention to things that really matter.
* e.g. [Eastern Airlines Flight 401](https://en.wikipedia.org/wiki/Eastern_Air_Lines_Flight_401)
  * pilots were preoccupied with fixing a burned out but unimportant indicator light
  * put the plane on autopilot, and *turned off alarms that they were descending (i.e. crashing)*
* It's possible to become hyperfocused and ignore important help messages, etc.
* Implications for UI: don't give people minutia to focus on.

### Automatic Actions
* If you practice something over and over again, eventually it becomes something that you just *do*, without thinking about it.
* You want as many activities as you can to be automatic, so that you can be more productive.
* e.g. it's hard to be a great programmer when you're spending all the time making sure you're typing correctly.

* Practice doesn't make perfect, it makes permanent.
* With practice, you get to clump a sequence of actions together into a single action.
* e.g. Tying your shoelaces

* When actions become automatic, it becomes hard to unlearn.
* e.g. if you're used to driving in the US (on the right), hard to adjust to driving in the UK (on the left)

* For UIs, this means that you should be consistent.
* For example, in a dialog box, the OK and cancel buttons should be in the same position, so people don't have to think about where it is.
* You can also force people *not* to use their automatic actions
  * e.g. Adobe Lightroom, the confirm dialog for deleting photos from the disk is in an unusual place, so that the button you have the most chance of doing automatically is the cancel button.
